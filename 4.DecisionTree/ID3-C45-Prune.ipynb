{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剪枝过程 优化结构化损失：\n",
    "$C_\\alpha(T)=C(T)+\\alpha|T|$\n",
    "\n",
    "$C(T)=\\sum_{t=1}^{T}N_tH_t(T) = \\sum_{t=1}^{|T|}N_t[-\\sum_{k=1}^{K}\\frac{N_{tk}}{N_t}log_2 \\frac{N_{tk}}{N_t}]$\n",
    "\n",
    "T为叶子结点的个数，计算在所有叶子节点上熵的加权和，然后进行叶子结点的合并，比较其损失大小，如果合并后损失更小，则两个叶子节点向上一层合并。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits,load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data,dtype=int)\n",
    "df['label'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  label\n",
       "0  5  3  1  0      0\n",
       "1  4  3  1  0      0\n",
       "2  4  3  1  0      0\n",
       "3  4  3  1  0      0\n",
       "4  5  3  1  0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self,feature_name=None,label=None,is_leaf=False,instances=None):\n",
    "        \n",
    "        self.childs = {}   #存储当前特征的unique值对应的子树的链接\n",
    "        self.feature_name = feature_name  #当前选用的特征\n",
    "        \n",
    "        self.label = label   \n",
    "        self.is_leaf = is_leaf     # 是否叶子节点\n",
    "        self.instances = instances #在叶子节点存储对应的实体，便于后续的剪枝操作计算熵\n",
    "        \n",
    "    def add_child(self,val,node):\n",
    "        self.childs[val] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, method=\"id3\",epsilon=0.1,alpha=1.0):\n",
    "        if method != \"id3\" and method != \"c4.5\":raise ValueError(\"Invalid Decision Tree method!\")\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.method = method\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def entropy(self,series):\n",
    "        count = series.groupby(series).count()\n",
    "        count /= count.sum()\n",
    "        probs = np.array(count)\n",
    "        return -np.sum(probs*np.log2(probs))\n",
    "    \n",
    "    def conditional_entropy(self,data):\n",
    "        \n",
    "        # 每个特征的值分布的权重 |Di|/D\n",
    "        feature_value_cnt = data.iloc[:,0].groupby(data.iloc[:,0]).count()\n",
    "        feature_value_weight = feature_value_cnt/feature_value_cnt.sum()\n",
    "        \n",
    "        # 对该特征，同样值筛选出来的子数据集中标签的熵，即该特征值的筛选对标签的熵有没有降低作用\n",
    "        H_D_i = data.groupby(data.iloc[:,0]).apply(lambda x:self.entropy(x['label']))\n",
    "        return np.sum(feature_value_weight * H_D_i)\n",
    "    \n",
    "    def info_gain(self,data):\n",
    "        H_D = self.entropy(data['label'])\n",
    "        H_D_given_X = self.conditional_entropy(data)\n",
    "        g_D_A = H_D - H_D_given_X\n",
    "        if self.method == \"c4.5\":\n",
    "            H_A_D = self.entropy(data.iloc[:,0])\n",
    "            g_D_A /= H_A_D\n",
    "        return g_D_A\n",
    "    \n",
    "    def calc_info_gain(self,data,features=None):\n",
    "        max_feature,max_gain = None,0\n",
    "        for feature_name in features:\n",
    "            gain = self.info_gain(data[[feature_name,'label']])\n",
    "            if gain > max_gain:\n",
    "                max_feature = feature_name\n",
    "                max_gain = gain\n",
    "        return max_feature,max_gain\n",
    "    \n",
    "    def create_tree(self,data,features):\n",
    "        \n",
    "        labels = data['label']\n",
    "        \n",
    "        # base case: no other features \n",
    "        if len(features) == 0:\n",
    "            label = labels.value_counts().sort_values(ascending=False).index[0]\n",
    "            return TreeNode(label=label,is_leaf=True,instances=data)\n",
    "        \n",
    "        # base case: one class\n",
    "        if len(np.unique(labels)) == 1:\n",
    "            return TreeNode(label=list(labels)[0],is_leaf=True,instances=data)\n",
    "        \n",
    "        #calc info gain by features\n",
    "        feature_name,max_gain = self.calc_info_gain(data,features=features)\n",
    "        \n",
    "        # pre prune\n",
    "        if max_gain < self.epsilon:\n",
    "            label = labels.value_counts().sort_values(ascending=False).index[0]\n",
    "            return TreeNode(label=label,is_leaf=True,instances=data)\n",
    "        \n",
    "\n",
    "        node = TreeNode(feature_name=feature_name,is_leaf=False)\n",
    "        #递归调用，根据特征值的不同划分数据集并构造子树\n",
    "        features -= set([feature_name])\n",
    "        unique_vals = data[feature_name].unique()\n",
    "        for val in unique_vals:\n",
    "            sub_data = data.loc[data[feature_name]==val]\n",
    "            sub_tree = self.create_tree(sub_data,features)\n",
    "            node.add_child(val,sub_tree)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def fit(self,data):\n",
    "        self.columns = set(data.iloc[:,:-1].columns)\n",
    "        self.tree = self.create_tree(data,self.columns)\n",
    "        \n",
    "    def predict(self,data):\n",
    "        res = []\n",
    "        for i in range(len(data)): \n",
    "            instance = data.iloc[i]\n",
    "            node = self.tree\n",
    "            while node.is_leaf == False:\n",
    "                val = instance[node.feature_name]\n",
    "                node = node.childs[val]\n",
    "            res.append(node.label)\n",
    "        return res\n",
    "    \n",
    "    def printTree(self,node,layer=0):\n",
    "        print(\"{}layer: {} feature:{}\".format('\\t'*layer,layer,node.feature_name))\n",
    "        for key,val in node.childs.items():\n",
    "            if val.is_leaf == True:\n",
    "                print(\"{}Leaf Node,val={}\".format('\\t'*layer,key))\n",
    "        for key,val in node.childs.items():\n",
    "            if val.is_leaf == False:\n",
    "                print(\"{}partition node,feature:{}\".format('\\t'*layer,val.feature_name))\n",
    "                self.printTree(val,layer+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 树结构的打印，当把epsilon调低了之后在第二层生成了两个子树\n",
    "- 预剪枝：通过控制epsilon来限制不生成复杂度较高的子树\n",
    "- 后剪枝：通过结构损失最小化来合并过于复杂的子树\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC score:0.9619047619047619,cost time [0.1690974235534668]s\n",
      "layer: 0 feature:2\n",
      "Leaf Node,val=1\n",
      "Leaf Node,val=6\n",
      "Leaf Node,val=4\n",
      "Leaf Node,val=5\n",
      "Leaf Node,val=3\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set = train_test_split(df,test_size=0.7,random_state=6)\n",
    "test_X,test_Y = test_set.iloc[:,:-1],test_set['label']\n",
    "\n",
    "import time\n",
    "\n",
    "stime = time.time()\n",
    "model = DecisionTree(method='id3',epsilon=1,alpha=1)\n",
    "model.fit(train_set)\n",
    "\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "etime = time.time()\n",
    "print(\"ACC score:{},cost time [{}]s\".format(accuracy_score(test_Y,preds),etime-stime))\n",
    "model.printTree(model.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC score:0.8571428571428571,cost time [0.21031856536865234]s\n",
      "layer: 0 feature:2\n",
      "Leaf Node,val=1\n",
      "Leaf Node,val=6\n",
      "Leaf Node,val=3\n",
      "partition node,feature:0\n",
      "\tlayer: 1 feature:0\n",
      "\tLeaf Node,val=5\n",
      "\tLeaf Node,val=6\n",
      "\tLeaf Node,val=7\n",
      "\tLeaf Node,val=4\n",
      "partition node,feature:3\n",
      "\tlayer: 1 feature:3\n",
      "\tLeaf Node,val=2\n",
      "\tLeaf Node,val=1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "stime = time.time()\n",
    "model = DecisionTree(method='id3',epsilon=0.01,alpha=1)\n",
    "model.fit(train_set)\n",
    "\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "etime = time.time()\n",
    "print(\"ACC score:{},cost time [{}]s\".format(accuracy_score(test_Y,preds),etime-stime))\n",
    "model.printTree(model.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对上面epsilon=0.01的模型进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(series):\n",
    "    count = series.groupby(series).count()\n",
    "    count /= count.sum()\n",
    "    probs = np.array(count)\n",
    "    return -np.sum(probs*np.log2(probs))\n",
    "\n",
    "\n",
    "def prune(root,alpha):\n",
    "    if not root.childs:\n",
    "        return None\n",
    "    \n",
    "    for node in root.childs.values():\n",
    "        if node.is_leaf == False:\n",
    "            prune(node,alpha)\n",
    "    \n",
    "    # prune when sublings are all leaf node\n",
    "    PRUNE = True\n",
    "    for node in root.childs.values():\n",
    "        if node.is_leaf == False:\n",
    "            PRUNE = False\n",
    "            break\n",
    "    if PRUNE:\n",
    "        all_instances = []\n",
    "        old_entropys = 0\n",
    "        for node in root.childs.values():\n",
    "            all_instances.append(node.instances)\n",
    "            old_entropys += len(node.instances)*entropy(node.instances['label'])+alpha\n",
    "        all_instances = pd.concat(all_instances)\n",
    "        new_entropys = len(all_instances)*entropy(all_instances['label']) - alpha * (len(root.childs)-1)\n",
    "        if new_entropys < old_entropys:\n",
    "            root.is_leaf = True\n",
    "            root.childs = {}\n",
    "            root.label = all_instances['label'].value_counts().sort_values(ascending=False).index[0]\n",
    "            root.instances = all_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer 2 子树被剪掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0 feature:2\n",
      "Leaf Node,val=1\n",
      "Leaf Node,val=6\n",
      "Leaf Node,val=4\n",
      "Leaf Node,val=5\n",
      "Leaf Node,val=3\n",
      "ACC score:0.9619047619047619,cost time [0.01197052001953125]s\n"
     ]
    }
   ],
   "source": [
    "prune(model.tree,model.alpha)\n",
    "model.printTree(model.tree)\n",
    "\n",
    "stime = time.time()\n",
    "preds = model.predict(test_X)\n",
    "etime = time.time()\n",
    "print(\"ACC score:{},cost time [{}]s\".format(accuracy_score(test_Y,preds),etime-stime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
